# =====================================================================
# Local: REAL Azure OpenAI backends
# Copy this file to config/appsettings.<env>.env and adjust values.
# Deploy with: docker compose -f docker-compose.local.yml up
#
# Indexing rules:
# - Backends use contiguous indices 0,1,2,... (no gaps). Add as many as you need.
# - Consumers (client API keys) use contiguous indices 0,1,2,... (no gaps).
# =====================================================================
# Secrets (API keys) now live in config/secrets.<env>.env.

## Logging verbosity for APISIX error log
## Allowed: debug | info | notice | warn | error | crit | alert | emerg
## Example: warn
# APISIX_LOG_LEVEL=info

## Enable APIM E2E test mode (adds config API proxy + test routes; requires config API sidecar)
## Allowed: true | false
## Default: false
# GATEWAY_E2E_TEST_MODE=false

# -----------------------------
# APIM gateway logger (Azure Monitor via DCR)
# Custom overrides are optional; defaults come from Container Apps injected env (identity_endpoint/identity_header/azure_client_id)
# APIM_GATEWAY_LOGS_INGEST_URI=
# APIM_GATEWAY_LOGS_STREAM=Custom-APISIXGatewayLogs
# APIM_GATEWAY_LOGS_INCLUDE_REQ_BODY=false
# APIM_GATEWAY_LOGS_BATCH_MAX_SIZE=100
# APIM_GATEWAY_LOGS_BATCH_FLUSH_INTERVAL=5
# APIM_GATEWAY_LOGS_BATCH_MAX_RETRY=5
# APIM_GATEWAY_LOGS_TIMEOUT_MS=10000
# APIM_GATEWAY_LOGS_MSI_CLIENT_ID=
# APIM_GATEWAY_LOGS_MSI_ENDPOINT=

# -----------------------------
## Azure OpenAI backends (contiguous indices 0..N; do not skip)
## Each backend needs ENDPOINT + KEY; PRIORITY (higher preferred) and WEIGHT (split among equal PRIORITY) optional.
## Allowed (ENDPOINT_N): https URL
## Allowed (PRIORITY_N): integer >=0 (bigger = more preferred)
## Allowed (WEIGHT_N): integer >=1 (distribution within same PRIORITY)
## Example (primary): AZURE_OPENAI_ENDPOINT_0=https://ptu.openai.azure.com
## Example (fallback): AZURE_OPENAI_ENDPOINT_1=https://payg.openai.azure.com
## Docs: https://apisix.apache.org/docs/apisix/terminology/upstream/ | https://docs.api7.ai/apisix/key-concepts/upstreams/
# -----------------------------
# AZURE_OPENAI_ENDPOINT_0=https://ptu.openai.azure.com
# AZURE_OPENAI_PRIORITY_0=1
# AZURE_OPENAI_WEIGHT_0=2

# AZURE_OPENAI_ENDPOINT_1=https://payg.openai.azure.com
# AZURE_OPENAI_PRIORITY_1=5
# AZURE_OPENAI_WEIGHT_1=1

# -----------------------------
## Gateway authentication (API consumers; contiguous indices 0..N)
## Enable API key requirement
## Allowed: true | false
# GATEWAY_REQUIRE_AUTH=false

## Consumer name (display / logging)
## Allowed: non-empty string
## Example: test-client-0
# GATEWAY_CLIENT_NAME_0=test-client-0

## Second consumer name
## Allowed: non-empty string
## Example: test-client-1
# GATEWAY_CLIENT_NAME_1=test-client-1

# -----------------------------
## Load balancing algorithm
## Allowed: roundrobin | chash
## Example: roundrobin
# lb_alg=roundrobin

# -----------------------------
## APISIX Active Health Checks
## Enable active health checks against upstream backends
## Allowed: true | false
# APISIX_ACTIVE_HEALTH_CHECKS=false

## Protocol used for health probe requests
## Allowed: http | https
## Example: https
# APISIX_ACTIVE_HEALTH_CHECK_SCHEME=https

## Verify SSL certificates
## Allowed: true | false
## Example: false
# APISIX_ACTIVE_HEALTH_CHECK_VERIFY_CERT=true

## Path requested for health checking
## Allowed: absolute path
## Example: /openai/v1/models
# APISIX_ACTIVE_HEALTH_CHECK_PATH=/openai/v1/models

## Per-request timeout for health probe
## Allowed: integer seconds >0
## Example: 1
# APISIX_ACTIVE_HEALTH_CHECK_TIMEOUT=1

## Interval (seconds) between checks for healthy backends
## Allowed: integer seconds >0
## Example: 10
# APISIX_ACTIVE_HEALTH_CHECK_HEALTHY_INTERVAL=10

## Interval (seconds) between checks for unhealthy backends
## Allowed: integer seconds >0
## Example: 5
# APISIX_ACTIVE_HEALTH_CHECK_UNHEALTHY_INTERVAL=5

# -----------------------------
## Cross-Origin Resource Sharing (browser clients)
## Enable CORS processing
## Allowed: true | false
# ENABLE_CORS=false

## Allowed origins (comma list or *)
## Allowed: * | origin list
## Example: https://app.example.com,https://admin.example.com
# CORS_ALLOW_ORIGINS=*

## Allowed HTTP methods
## Allowed: comma-separated list
## Example: GET,POST,PUT,DELETE,OPTIONS
# CORS_ALLOW_METHODS=GET,POST,PUT,DELETE,OPTIONS

## Allowed request headers
## Allowed: * | header list
## Example: Content-Type,Authorization
# CORS_ALLOW_HEADERS=*

## Headers exposed to browser
## Allowed: * | header list
## Example: X-Request-ID
# CORS_EXPOSE_HEADERS=*

## Preflight cache max age (seconds)
## Allowed: integer >=0
## Example: 3600
# CORS_MAX_AGE=3600

## Allow credentialed requests
## Allowed: true | false
# CORS_ALLOW_CREDENTIALS=true

# -----------------------------
## Rate limiting (smooth request rate; 429 if exceeded)
## Enable request rate limiter
## Allowed: true | false
# ENABLE_RATE_LIMIT=false

## Allowed average rate (requests per second)
## Allowed: float >0
## Example: 100.0
# RATE_LIMIT_RATE=100.0

## Burst capacity (tokens) beyond average rate
## Allowed: integer >=0
## Example: 20
# RATE_LIMIT_BURST=20

# -----------------------------
## Quota limiting (hard cap per fixed window; 429 if exceeded)
## Enable quota limiter
## Allowed: true | false
# ENABLE_QUOTA=false

## Max requests allowed in window
## Allowed: integer >0
## Example: 1000
# QUOTA_COUNT=1000

## Window size (seconds)
## Allowed: integer >0
## Example: 60
# QUOTA_TIME_WINDOW=60

# -----------------------------
## AI rate limiting (token-aware: tokens or requests per window)
## Enable AI rate limiter for OpenAI routes
## Allowed: true | false
# ENABLE_AI_RATE_LIMIT=false

## Limiting strategy (token-aware or request-count)
## Allowed: total_tokens | req
## Default: total_tokens
# AI_RATE_LIMIT_STRATEGY=total_tokens

## Window size for AI rate limit (seconds)
## Allowed: integer >0
## Default: 60
# AI_RATE_LIMIT_WINDOW_SECONDS=60

## High-priority bucket tokens per window (default routes)
## Allowed: integer >0
## Default: 200
# AI_RATE_LIMIT_HIGH_LIMIT=200

## Low-priority bucket tokens per window (prio-low routes)
## Allowed: integer >0
## Default: 20
# AI_RATE_LIMIT_LOW_LIMIT=20

## HTTP status returned when AI rate limit is exceeded
## Allowed: integer HTTP status code
## Default: 503
# AI_RATE_LIMIT_REJECT_CODE=503

## Message returned when AI rate limit is exceeded
## Allowed: string
## Default: "rate limited"
# AI_RATE_LIMIT_REJECT_MESSAGE="rate limited"

# -----------------------------
## IP allow / deny restrictions
## Enable IP restriction plugin
## Allowed: true | false
# ENABLE_IP_RESTRICTION=false

## Whitelist CIDRs (comma list)
## Allowed: comma-separated CIDRs
## Example: 10.0.0.0/8,172.16.0.0/12
# IP_WHITELIST=

## Blacklist CIDRs (comma list)
## Allowed: comma-separated CIDRs
## Example: 203.0.113.0/24
# IP_BLACKLIST=

# -----------------------------
## OpenTelemetry Collector (sidecar telemetry export)
## Controls resource attributes, scraping parameters, and Azure Monitor exporters.
# -----------------------------

## Collector log verbosity
## Allowed: debug | info | warn | error
## Example: info
# OTEL_LOG_LEVEL=info

## Trace sampling rate (0.0â€“1.0). Use lower values in prod to cut cost.
OTEL_SAMPLE_RATE=0.1

## Enable verbose debug exporter (mirrors payloads to stdout)
## Allowed: true | false
# ENABLE_DEBUG_EXPORTER=false

## Logical service name reported via telemetry
## Allowed: non-empty string
## Example: apisix-gateway
# OTEL_SERVICE_NAME=apisix-gateway

## Service version resource attribute
## Allowed: string (semantic version recommended)
## Example: 1.0.0
# SERVICE_VERSION=1.0.0

## Deployment environment resource attribute
## Allowed: string (e.g., dev | test | prod)
## Example: test
# ENVIRONMENT=test

## Cloud platform resource attribute
## Allowed: string identifier
## Example: azure_container_apps
# CLOUD_PLATFORM=azure_container_apps

## Cluster label applied to exported metrics
## Allowed: string identifier
## Example: apisix-gateway
# CLUSTER_NAME=apisix-gateway

## Batch processor timeout
## Allowed: Go duration (e.g., 5s, 1m)
## Example: 10s
# OTEL_BATCH_TIMEOUT=10s

## Batch processor size (number of spans/logs/metrics)
## Allowed: integer >0
## Example: 1024
# OTEL_BATCH_SIZE=1024

## Memory limiter ceiling (MiB)
## Allowed: integer >0
## Example: 512
# OTEL_MEMORY_LIMIT_MIB=512

## Memory limiter spike allowance (MiB)
## Allowed: integer >=0
## Example: 128
# OTEL_MEMORY_SPIKE_MIB=128

## APISIX log file path scraped by filelog receiver
## Allowed: absolute path
## Example: /usr/local/apisix/logs/genai_access.json
# APISIX_LOGS_PATH=/usr/local/apisix/logs/genai_access.json

## Prometheus scrape target (host:port)
## Allowed: host:port string
## Example: 127.0.0.1:9091
# APISIX_GATEWAY_ENDPOINT=127.0.0.1:9091

## Prometheus metrics path
## Allowed: absolute path
## Example: /apisix/prometheus/metrics
# APISIX_METRICS_PATH=/apisix/prometheus/metrics

## Scrape interval
## Allowed: Go duration
## Example: 30s
# PROMETHEUS_SCRAPE_INTERVAL=30s

## Scrape timeout
## Allowed: Go duration less than interval
## Example: 10s
# PROMETHEUS_SCRAPE_TIMEOUT=10s

## Application Insights connection string (usually stored in Key Vault)
## Allowed: full Application Insights connection string
## Example: InstrumentationKey=...;IngestionEndpoint=...
# APPLICATIONINSIGHTS_CONNECTION_STRING=

## Azure Monitor managed Prometheus remote-write endpoint (base URL without /api/v1/write)
## Allowed: https URL
## Example: https://<workspace>.<region>.metrics.ingest.monitor.azure.com/.../streams/Microsoft-PrometheusMetrics
# AZURE_MONITOR_WORKSPACE_ENDPOINT=

## Managed identity client ID used for Azure Monitor auth (set automatically when running in ACA)
## Allowed: UUID
## Example: f9eabfa4-2b67-4c39-abe2-4bf6b457d1ef
# AZURE_CLIENT_ID=

## Prometheus remote-write tenant label
## Allowed: string identifier
## Example: anonymous
# PROMETHEUS_REMOTE_WRITE_ORG_ID=anonymous

## Enable remote-write queue
## Allowed: true | false
# PROMETHEUS_REMOTE_WRITE_QUEUE_ENABLED=true

## Remote-write queue size
## Allowed: integer >0
## Example: 10000
# PROMETHEUS_REMOTE_WRITE_QUEUE_SIZE=10000

## Remote-write worker count
## Allowed: integer >0
## Example: 5
# PROMETHEUS_REMOTE_WRITE_QUEUE_CONSUMERS=5

## Enable retry on failure
## Allowed: true | false
# PROMETHEUS_REMOTE_WRITE_RETRY_ENABLED=true

## Initial retry interval
## Allowed: Go duration
## Example: 5s
# PROMETHEUS_REMOTE_WRITE_RETRY_INITIAL=5s

## Max retry interval
## Allowed: Go duration
## Example: 30s
# PROMETHEUS_REMOTE_WRITE_RETRY_MAX=30s

## Max retry elapsed time
## Allowed: Go duration
## Example: 5m
# PROMETHEUS_REMOTE_WRITE_RETRY_MAX_ELAPSED=5m

## Remote-write request timeout
## Allowed: Go duration
## Example: 30s
# PROMETHEUS_REMOTE_WRITE_TIMEOUT=30s
