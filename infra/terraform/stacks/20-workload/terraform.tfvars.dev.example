# Environment-specific tfvars for 20-workload (dev)

subscription_id = "00000000-0000-0000-0000-000000000000"
tenant_id       = "11111111-1111-1111-1111-111111111111"

environment_code = "dev"
location         = "eastus"
workload_name    = "apisix"
identifier       = ""

platform_resource_group_name = ""
platform_acr_name            = ""
key_vault_name               = ""
aca_managed_identity_id      = ""

state_resource_group_name  = ""
state_storage_account_name = ""
state_container_name       = "tfstate"
foundation_state_blob_key  = "dev/10-platform.tfstate"
openai_state_blob_key      = "dev/15-foundry.tfstate"

app_settings = {
  # ═════════════════════════════════════════════════════════════════════════════
  # Development configuration (non-secret)
  # Copy this example to terraform.tfvars.dev (or dev.tfvars) and adjust values.
  # Secrets belong in the `secrets` map below.
  #
  # Indexing rules:
  # - Backends use contiguous indices 0,1,2,... (no gaps). Add as many as you need.
  # - Consumers (client API keys) use contiguous indices 0,1,2,... (no gaps).
  # ═════════════════════════════════════════════════════════════════════════════

  ## Logging verbosity for APISIX error log
  ## Allowed: debug | info | notice | warn | error | crit | alert | emerg
  ## Default: warn
  ## Example: warn
  APISIX_LOG_LEVEL = "info"

  ## Enable APIM E2E test mode (adds config API proxy + test routes; requires config API sidecar)
  ## Allowed: true | false
  ## Default: false
  # GATEWAY_E2E_TEST_MODE=false

  # -----------------------------
  # APIM gateway logger (Azure Monitor via DCR)
  # Custom overrides are optional; defaults come from Container Apps injected env (identity_endpoint/identity_header/azure_client_id)
  # APIM_GATEWAY_LOGS_INGEST_URI=
  # APIM_GATEWAY_LOGS_STREAM=Custom-APISIXGatewayLogs
  # APIM_GATEWAY_LOGS_INCLUDE_REQ_BODY=false
  # APIM_GATEWAY_LOGS_BATCH_MAX_SIZE=100
  # APIM_GATEWAY_LOGS_BATCH_FLUSH_INTERVAL=5
  # APIM_GATEWAY_LOGS_BATCH_MAX_RETRY=5
  # APIM_GATEWAY_LOGS_TIMEOUT_MS=10000
  # APIM_GATEWAY_LOGS_MSI_CLIENT_ID=
  # APIM_GATEWAY_LOGS_MSI_ENDPOINT=

  # -----------------------------
  ## Azure OpenAI backends (contiguous indices 0..N; do not skip)
  ## Each backend needs ENDPOINT + KEY; PRIORITY (higher preferred) and WEIGHT (split among equal PRIORITY) optional.
  ## Allowed (ENDPOINT_N): https URL
  ## Allowed (PRIORITY_N): integer >=0 (bigger = more preferred)
  ## Allowed (WEIGHT_N): integer >=1 (distribution within same PRIORITY)
  ## Example (primary): AZURE_OPENAI_ENDPOINT_0=https://ptu.openai.azure.com
  ## Example (fallback): AZURE_OPENAI_ENDPOINT_1=https://payg.openai.azure.com
  ## Docs: https://apisix.apache.org/docs/apisix/terminology/upstream/ | https://docs.api7.ai/apisix/key-concepts/upstreams/
  # -----------------------------
  # AZURE_OPENAI_ENDPOINT_0=https://ptu.openai.azure.com
  # AZURE_OPENAI_PRIORITY_0=1
  # AZURE_OPENAI_WEIGHT_0=2

  # AZURE_OPENAI_ENDPOINT_1=https://payg.openai.azure.com
  # AZURE_OPENAI_PRIORITY_1=5
  # AZURE_OPENAI_WEIGHT_1=1

  # -----------------------------
  ## Gateway authentication (API consumers; contiguous indices 0..N)
  ## Enable API key requirement
  ## Allowed: true | false
  GATEWAY_REQUIRE_AUTH = "true"

  ## Consumer name (display / logging)
  ## Allowed: non-empty string
  ## Example: dev-client-0
  GATEWAY_CLIENT_NAME_0 = "dev-client-0"
  # GATEWAY_CLIENT_NAME_1=dev-client-1
  # GATEWAY_CLIENT_NAME_2=dev-client-2

  # -----------------------------
  ## Load balancing algorithm
  ## Allowed: roundrobin | chash
  ## Example: roundrobin
  # lb_alg=roundrobin

  # -----------------------------
  ## APISIX Active Health Checks
  ## Enable active health checks against upstream backends
  ## Allowed: true | false
  # APISIX_ACTIVE_HEALTH_CHECKS=false

  ## Protocol used for health probe requests
  ## Allowed: http | https
  ## Example: https
  # APISIX_ACTIVE_HEALTH_CHECK_SCHEME=https

  ## Verify SSL certificates
  ## Allowed: true | false
  ## Example: false
  # APISIX_ACTIVE_HEALTH_CHECK_VERIFY_CERT=true

  ## Path requested for health checking
  ## Allowed: absolute path
  ## Example: /openai/v1/models
  # APISIX_ACTIVE_HEALTH_CHECK_PATH=/openai/v1/models

  ## Per-request timeout for health probe
  ## Allowed: integer seconds >0
  ## Example: 1
  # APISIX_ACTIVE_HEALTH_CHECK_TIMEOUT=1

  ## Interval (seconds) between checks for healthy backends
  ## Allowed: integer seconds >0
  ## Example: 10
  # APISIX_ACTIVE_HEALTH_CHECK_HEALTHY_INTERVAL=10

  ## Interval (seconds) between checks for unhealthy backends
  ## Allowed: integer seconds >0
  ## Example: 5
  # APISIX_ACTIVE_HEALTH_CHECK_UNHEALTHY_INTERVAL=5

  # -----------------------------
  # AI proxy timeouts & logging
  # Tighten request budgets when needed; defaults here keep local dev generous.
  ## Connect timeout to upstream (seconds)
  AI_PROXY_CONNECT_TIMEOUT = "60"

  ## Send timeout (seconds)
  AI_PROXY_SEND_TIMEOUT = "300"

  ## Read timeout (seconds)
  AI_PROXY_READ_TIMEOUT = "300"

  ## Emit per-request summaries from ai-proxy (true = more logging noise)
  AI_PROXY_LOG_SUMMARIES = "true"

  # -----------------------------
  ## Cross-Origin Resource Sharing (browser clients)
  ## Enable CORS processing
  ## Allowed: true | false
  # ENABLE_CORS=false

  ## Allowed origins (comma list or *)
  ## Allowed: * | origin list
  ## Example: https://app.example.com,https://admin.example.com
  # CORS_ALLOW_ORIGINS=*

  ## Allowed HTTP methods
  ## Allowed: comma-separated list
  ## Example: GET,POST,PUT,DELETE,OPTIONS
  # CORS_ALLOW_METHODS=GET,POST,PUT,DELETE,OPTIONS

  ## Allowed request headers
  ## Allowed: * | header list
  ## Example: Content-Type,Authorization
  # CORS_ALLOW_HEADERS=*

  ## Headers exposed to browser
  ## Allowed: * | header list
  ## Example: X-Request-ID
  # CORS_EXPOSE_HEADERS=*

  ## Preflight cache max age (seconds)
  ## Allowed: integer >=0
  ## Example: 3600
  # CORS_MAX_AGE=3600

  ## Allow credentialed requests
  ## Allowed: true | false
  # CORS_ALLOW_CREDENTIALS=true

  # -----------------------------
  ## Rate limiting (smooth request rate; 429 if exceeded)
  ## Enable request rate limiter
  ## Allowed: true | false
  # ENABLE_RATE_LIMIT=false

  ## Allowed average rate (requests per second)
  ## Allowed: float >0
  ## Example: 100.0
  # RATE_LIMIT_RATE=100.0

  ## Burst capacity (tokens) beyond average rate
  ## Allowed: integer >=0
  ## Example: 20
  # RATE_LIMIT_BURST=20

  # -----------------------------
  ## Quota limiting (hard cap per fixed window; 429 if exceeded)
  ## Enable quota limiter
  ## Allowed: true | false
  # ENABLE_QUOTA=false

  ## Max requests allowed in window
  ## Allowed: integer >0
  ## Example: 1000
  # QUOTA_COUNT=1000

  ## Window size (seconds)
  ## Allowed: integer >0
  ## Example: 60
  # QUOTA_TIME_WINDOW=60

  # -----------------------------
  ## AI rate limiting (token-aware: tokens or requests per window)
  ## Enable AI rate limiter for OpenAI routes
  ## Allowed: true | false
  # ENABLE_AI_RATE_LIMIT=false

  ## Limiting strategy (token-aware or request-count)
  ## Allowed: total_tokens | req
  ## Default: total_tokens
  # AI_RATE_LIMIT_STRATEGY=total_tokens

  ## Window size for AI rate limit (seconds)
  ## Allowed: integer >0
  ## Default: 60
  # AI_RATE_LIMIT_WINDOW_SECONDS=60

  ## High-priority bucket tokens per window (default routes)
  ## Allowed: integer >0
  ## Default: 200
  # AI_RATE_LIMIT_HIGH_LIMIT=200

  ## Low-priority bucket tokens per window (prio-low routes)
  ## Allowed: integer >0
  ## Default: 20
  # AI_RATE_LIMIT_LOW_LIMIT=20

  ## HTTP status returned when AI rate limit is exceeded
  ## Allowed: integer HTTP status code
  ## Default: 503
  # AI_RATE_LIMIT_REJECT_CODE=503

  ## Message returned when AI rate limit is exceeded
  ## Allowed: string
  ## Default: "rate limited"
  # AI_RATE_LIMIT_REJECT_MESSAGE="rate limited"

  # -----------------------------
  ## IP allow / deny restrictions
  ## Enable IP restriction plugin
  ## Allowed: true | false
  # ENABLE_IP_RESTRICTION=false

  ## Whitelist CIDRs (comma list)
  ## Allowed: comma-separated CIDRs
  ## Example: 10.0.0.0/8,172.16.0.0/12
  # IP_WHITELIST=

  ## Blacklist CIDRs (comma list)
  ## Allowed: comma-separated CIDRs
  ## Example: 203.0.113.0/24
  # IP_BLACKLIST=

  # -----------------------------
  ## OpenTelemetry Collector (sidecar telemetry export)
  ## Controls resource attributes, scraping parameters, and Azure Monitor exporters.
  # -----------------------------

  ## Collector log verbosity
  ## Allowed: debug | info | warn | error
  ## Example: info
  # OTEL_LOG_LEVEL=info

  ## Trace sampling rate (0.0–1.0). Use lower values in prod to cut cost.
  OTEL_SAMPLE_RATE = "1.0"

  ## Enable verbose debug exporter (mirrors payloads to stdout)
  ## Allowed: true | false
  ENABLE_DEBUG_EXPORTER = "false"

  ## Logical service name reported via telemetry
  ## Allowed: non-empty string
  ## Example: apisix-gateway
  # OTEL_SERVICE_NAME=apisix-gateway

  ## Service version resource attribute
  ## Allowed: string (semantic version recommended)
  ## Example: 1.0.0
  # SERVICE_VERSION=1.0.0

  ## Deployment environment resource attribute
  ## Allowed: string (e.g., dev | test | prod)
  ## Example: test
  # ENVIRONMENT=test

  ## Cloud platform resource attribute
  ## Allowed: string identifier
  ## Example: azure_container_apps
  # CLOUD_PLATFORM=azure_container_apps

  ## Cluster label applied to exported metrics
  ## Allowed: string identifier
  ## Example: apisix-gateway
  # CLUSTER_NAME=apisix-gateway

  ## Batch processor timeout
  ## Allowed: Go duration (e.g., 5s, 1m)
  ## Example: 10s
  # OTEL_BATCH_TIMEOUT=10s

  ## Batch processor size (number of spans/logs/metrics)
  ## Allowed: integer >0
  ## Example: 1024
  # OTEL_BATCH_SIZE=1024

  ## Memory limiter ceiling (MiB)
  ## Allowed: integer >0
  ## Example: 512
  # OTEL_MEMORY_LIMIT_MIB=512

  ## Memory limiter spike allowance (MiB)
  ## Allowed: integer >=0
  ## Example: 128
  # OTEL_MEMORY_SPIKE_MIB=128

  ## APISIX log file path scraped by filelog receiver
  ## Allowed: absolute path
  ## Example: /usr/local/apisix/logs/genai_access.json
  # APISIX_LOGS_PATH=/usr/local/apisix/logs/genai_access.json

  ## Prometheus scrape target (host:port)
  ## Allowed: host:port string
  ## Example: 127.0.0.1:9091
  # APISIX_GATEWAY_ENDPOINT=127.0.0.1:9091

  ## Prometheus metrics path
  ## Allowed: absolute path
  ## Example: /apisix/prometheus/metrics
  # APISIX_METRICS_PATH=/apisix/prometheus/metrics

  ## Scrape interval
  ## Allowed: Go duration
  ## Example: 30s
  # PROMETHEUS_SCRAPE_INTERVAL=30s

  ## Scrape timeout
  ## Allowed: Go duration less than interval
  ## Example: 10s
  # PROMETHEUS_SCRAPE_TIMEOUT=10s

  ## Application Insights connection string (usually stored in Key Vault)
  ## Allowed: full Application Insights connection string
  ## Example: InstrumentationKey=...;IngestionEndpoint=...
  # APPLICATIONINSIGHTS_CONNECTION_STRING=

  ## Azure Monitor managed Prometheus remote-write endpoint (base URL without /api/v1/write)
  ## Allowed: https URL
  ## Example: https://<workspace>.<region>.metrics.ingest.monitor.azure.com/.../streams/Microsoft-PrometheusMetrics
  # AZURE_MONITOR_WORKSPACE_ENDPOINT=

  ## Managed identity client ID used for Azure Monitor auth (set automatically when running in ACA)
  ## Allowed: UUID
  ## Example: f9eabfa4-2b67-4c39-abe2-4bf6b457d1ef
  # AZURE_CLIENT_ID=

  ## Prometheus remote-write tenant label
  ## Allowed: string identifier
  ## Example: anonymous
  # PROMETHEUS_REMOTE_WRITE_ORG_ID=anonymous

  ## Enable remote-write queue
  ## Allowed: true | false
  # PROMETHEUS_REMOTE_WRITE_QUEUE_ENABLED=true

  ## Remote-write queue size
  ## Allowed: integer >0
  ## Example: 10000
  # PROMETHEUS_REMOTE_WRITE_QUEUE_SIZE=10000

  ## Remote-write worker count
  ## Allowed: integer >0
  ## Example: 5
  # PROMETHEUS_REMOTE_WRITE_QUEUE_CONSUMERS=5

  ## Enable retry on failure
  ## Allowed: true | false
  # PROMETHEUS_REMOTE_WRITE_RETRY_ENABLED=true

  ## Initial retry interval
  ## Allowed: Go duration
  ## Example: 5s
  # PROMETHEUS_REMOTE_WRITE_RETRY_INITIAL=5s

  ## Max retry interval
  ## Allowed: Go duration
  ## Example: 30s
  # PROMETHEUS_REMOTE_WRITE_RETRY_MAX=30s

  ## Max retry elapsed time
  ## Allowed: Go duration
  ## Example: 5m
  # PROMETHEUS_REMOTE_WRITE_RETRY_MAX_ELAPSED=5m

  ## Remote-write request timeout
  ## Allowed: Go duration
  ## Example: 30s
  # PROMETHEUS_REMOTE_WRITE_TIMEOUT=30s
}

secrets = {
  # Secrets (Key Vault seed values) — edit in your terraform.tfvars.<env> file.
  # These are written to Key Vault by deploy-workload; keep this file out of source control.

  # -----------------------------
  ## Azure OpenAI backends (API keys)
  ## Allowed (KEY_N): non-empty string (secret)
  # AZURE_OPENAI_KEY_0=
  # AZURE_OPENAI_KEY_1=

  # -----------------------------
  ## Gateway authentication (client API keys)
  ## Allowed: non-empty string
  ## Example: dev-key-0
  GATEWAY_CLIENT_KEY_0 = "dev-key-0"
  # GATEWAY_CLIENT_KEY_1=dev-key-1
  # GATEWAY_CLIENT_KEY_2=dev-key-2

  # -----------------------------
  # APIM gateway logger (Azure Monitor via DCR)
  # Optional MSI secret override; defaults to Container Apps injected IDENTITY_HEADER/MSI_SECRET
  # APIM_GATEWAY_LOGS_MSI_SECRET=
}

gateway_image = ""
hydrenv_image = ""

expose_gateway_public       = true
gateway_target_port         = 9080
gateway_cpu                 = 1.0
gateway_memory              = "2Gi"
gateway_http_concurrency    = 60
gateway_cpu_scale_threshold = 70
gateway_min_replicas        = 2
gateway_max_replicas        = 20

otel_collector_cpu    = 0.25
otel_collector_memory = "0.5Gi"

log_analytics_workspace_id              = ""
azure_monitor_workspace_id              = ""
azure_monitor_prometheus_endpoint       = ""
azure_monitor_prometheus_query_endpoint = ""
azure_monitor_prometheus_dcr_id         = ""
log_retention_days                      = 30
app_insights_connection_string          = ""

enable_alerts         = false
alert_action_group_id = ""

tags = {
  owner       = "platform-team"
  environment = "dev"
  workload    = "apisix"
}
